Computational complexity and philosophy

computational complexity, philo, en cours
===

What might computational complexity have to do with philosophy? This is a write-up of my usual (informal) explanation at parties.

In short: philosophical theories often require a notion of the \emph{difficulty} of an information-processing task, and computational complexity is a well-developed measure of such difficulty.

\section*{Philosophy and difficulty.}
In philosophy and allied disciplines, questions about the difficulty of reasoning and other forms of information processing often arise. I don’t propose here to argue for any exciting philosophical claims, but rather to show that what I hope are fairly plausible philosophical arguments lead us to the question: how hard is such-and-such task?
\begin{itemize}
    \item \emph{Right and wrong.} It’s uncontroversial that knowledge and ignorance have at least some significance to questions of right and wrong. A simple and banal example: if a guest is allergic to a certain ingredient, I am cooking for them, and I leave the ingredient in the stew, it matters whether I knew of the allergy.
    
    Question: When someone does something, and is ignorant of a fact, what effect does that ignorance have on the rightness or wrongness of their action?

    A straightforward, if clearly wrong, answer is: ‘when someone does something, but would not have done it had they not been ignorant of a fact, what they did cannot have been wrong: ignorance of that fact completely excuses them’. Ignorance might not excuse a restaurant owner who unexpectedly includes a common allergen in a recipe in which it does not commonly appear (e.g. peanuts in a fruit salad).

    Part of a better answer will involve how reasonable it is to expect knowledge of the fact concerned. Suppose I slam a door open into someone. Consider the fact that someone is just behind the door (and will be injured if it is opened suddenly). If the door is to my own bedroom, it doesn’t seem reasonable to expect me to have checked for someone behind it. If the door opens into a busy corridor (and I know that), I really ought to have checked.

    Plausibly: (1) it is unreasonable to expect someone to know a fact impossible to learn and (2) ignorance of that fact is generally a good excuse. Suppose that one knows God will eradicate malaria if (and only if) one correctly predicts which way a coin He (fairly) tosses will come up. If one were, somehow, to know which way it will come up, it would plausibly be wrong to guess otherwise; otherwise, it is hard to see how guessing incorrectly is (morally) wrong.

    Analogously, perhaps (1) it is unreasonable to expect someone to know a fact that is very difficult (not just impossible) to learn and (2) ignorance of that fact is, to that extent, a good excuse. We can contrive similar examples by varying the example above: one could be asked to determine the truth of a seemingly intractable mathematical cojecture. But less contrived examples are not so far removed from the everyday. Consider political choices. A minister who stubbornly orders a dam not to be opened even though engineers tell him it will collapse, killing thousands, has no claim to the excuse of ignorance: it was not difficult for him to come to the truth. Had the engineers said that the considerations were evenly weighed, the dam had a good chance of withstanding the weight, and thousands would die either way, we might view his choice as a tragedy rather than a crime.
    % \item \emph{Rationality.} Philosophers are interested by how to rationally choose, and (very) general rules about how to do so: what salary should one accept? how many children should one have? is there a rational way to play poker? with friends? in a casino? and so on.
    
    % Sometimes, we are interested in what an ideal reasoner, with few or no limits on their abilities, would do. For example, why does God tolerate evil in the world? An answer that suggests He doesn’t know about it, or can’t spot some obvious way of eradicating it, would not be satisfactory. But sometimes we are interested in notions of rationality that are more achievable, given our own cognitive limitations. Such notions might be more useful in guiding our own actions: what is the best we can do, given that we aren’t as good as reasoning as God? If a certain form of reasoning would be too hard, the dictates of rationality (in this, more down to earth, sense) should not require us to carry it out. 
    \item \emph{Cognition.} We process information through various cognitive processes: perception, inference, language processing, and so on. From auditory inputs we come to awareness of sentences uttered by others; from knowledge of some facts we come to know other facts (e.g. if either A or B is the case, when we come to know that A isn’t the case, we typically infer B); and from rays of light in the retina, we apprehend ordinary objects (tables, chairs) before us.

    Philosophers (and others) are often intersted in how we carry out such information-processing. A natural, if inchoate, view is that theories that suggest very difficult forms of information processing should be treated with suspicion. Consider a (quite incredible) theory that says: (1) we retain a record of all utterances we ever hear, and (2) our competent use of language involves exhaustively searching these past utterances: e.g., in determining whether a sentence is grammatical, we exhaustively search for a similar sentence we have heard before. To retain such a record would be very difficult, and we might suspect that this is not, on those grounds, a very good theory.
    
    This is a rather inchoate principle in that (1) it does not tell us how suspicious we should be; but, leaving that aside, (2) to apply this principle more generally, we need to know what should count as difficult.
\end{itemize}
\section*{Computational complexity.}
Computer science offers one measure of the difficulty of a task: computational complexity.

Consider a list containing two numbers. The task is to sort the list in ascending order, by repeated use of the following operation: one compares two adjacent numbers, and, if they are in the wrong order, one swaps them (let us call these ‘comparisons’). How many comparisons do we need to sort this list of two elements? Obviously: one.

Suppose that the list contains three elements. How many comparisons do we need to sort the list? One comparison isn’t enough: it doesn’t allow us to even consider one of the numbers. What about two comparisons? If we are lucky, two comparisons might work: to \emph{verify} that the list [1,2,3] is sorted, we only need to note that 1 < 2, and 2 < 3. But two comparisons will not, in fact, suffice. Every time we make a comparison, there are at most two possibilities as to what we do (either we swap the numbers or we don’t). With two comparisons, there are therefore four possibilities as to the order in which we put the initial elements. But there are \emph{six} possible correct orders (3 × 2 × 1). So we need \emph{three} comparisons.

What if we don’t know how many elements there are in the list? Suppose that there are \(n\) elements; there could be five, or a hundred, or a million. How many comparisons, in terms of \(n\), do we need? A very pessimistic answer would be: \(2^n\). That would mean that the number of comparisons would double every time we add a number to the list. A very optimistic answer would be: \(2n\). That would mean that the additional number of comparisons needed from adding an element to the list would be fixed. That is the sort of question that \emph{computational complexity} answers. A classic result in complexity theory is that to sort a list requires neither \(2^n\) nor \(2n\) comparisons, but rather a function that grows in close proportion to \(n \log n\) \parencite{hoare1962}.

What does ‘in close proportion’ mean here? Consider algorithms sorting lists with \(n\) elements. One requires \(n + 100\) comparisons, another \(n^2\). On small inputs, the first input is better (e.g. 2² < 2 + 100). On large inputs, however, the second algorithm is better. In complexity theory, we typically ignore constants like \(100\). Consider another algorithm: one takes \(1000n\) comparisons, the other \(n^2\). Again, the first is only better on smaller inputs. In complexity theory, we also typically ignore these constant multiplicands. So, in the notation of computational complexity, we write that sorting a list takes \(O(n \log n)\) comparisons, which could mean it takes \(n \log n + 1000\) or \(25n \log n + 3n + 25\) or \(30n \log n\) comparisons.

Complexity theory does not only concern lists; it considers the difficulty of problems, in general, in terms of their \emph{size}. For example: what’s the shortest route that visits each of \(n\) cities at least once? Given \(n\) statements, are they contradictory?

In these terms, what counts as easy? The answer is typically \emph{polynomial time}. What does that mean? A \emph{polynomial-time} algorithm that solves a problem of size \(n\) in polynomial time solves it in \(n^c\) time, where \(c\) is an arbitrary but \emph{fixed} number. List-processing algorithms that take \(n^5, 2n+7, n+\log n,\) and \(3\) comparisons to finish take polynomial time. If they take \(2^n\) comparisons, they don’t.

Polynomial time is very mathematically elegant. A natural worry from the foregoing is: when should we consider an operation to really be a single operation, and when should we consider it really to be several distinct operations? If I sort cards with numbers on them into a single list, I might look at three cards at the same time, rather than the two that the model above required. The problems that can be solved in polynomial time do not change when we make seemingly reasonable changes to the model like this. (I think that, unnoticed, a \href{https://vignetterie.org/vignettes/invariance.html}{philosopher} was the first to formulate something like this view.) Polynomial time therefore seems a fairly reasonable way to answer the question: what counts as difficult?

\section*{Applications.}
Although philosophers are usually more familiar with logic and probability than complexity theory, some philosophical work has appealed to it. (See \textcites{aaronson2013}{szymanik2018}{vanrooij2019}{dean2021} for surveys.) Here is an incomplete list.
\begin{itemize}
\item \emph{Logic and psychology.} Is logical inferene a good model of human reasoning? \textcite{levesque1988} suggests that to naïvely appeal to classical logic is unwise, because reasoning in classical logic is too (complexity-theoretically) hard. But some modified logical descriptions of how humans reason only require polynomial time.
\item \emph{Cognition.} \textcite{vanrooij2008} suggests that cognitive-scientific theories should be held to a \emph{tractable cognition thesis}: tractable cognitive processes take polynomial time.
\item \emph{Linguistics and philosophy of language.} \textcite[§ 6.2]{ristad1993} argues that language computations must be complexity-theoretically difficult, and research about language should focus on how we nevertheless are reasonably successful, rather than explaining those errors that do arise on the assumption that language computations are easy.

Some Chomskyans \href{https://vignetterie.org/vignettes/thesis-proposal.html}{develop} Chomsky’s ‘poverty of the stimulus’ argument in terms of complexity too. Without innate knowledge of language, learning language would be too hard—therefore, we have such innate knowledge.
\end{itemize}
\section*{Some objections.}
One natural worry about the identification of polynomial time with feasible tasks is: can’t polynomial functions still be very large? and what if they’re much larger than an exponential function on reasonable inputs?

This isn’t very common in practice: most polynomial algorithms are manageable (and those that aren’t tend to be improved), although there are exceptions \parencite{helfgott2019}. There is one more reason that this isn’t common in practice, which is that computers themselves improve. \textcite{moore1965}’s law held for a long time, but even after it ceased to hold, improvements have continued. What were once unrealistically large inputs are now comonplace. In studying humans, this last assumption does not hold. Although human cognitive capacities plausibly have improved over time, they have not done so by the many orders of magnitude computers have.

A more general worry is that the study of computational complexity concerns difficulty with respect to problems of \emph{unbounded size}. Humans, on the other hand, often are confronted with problems within fairly small constraints. Consider a problem \textcite[cap 4]{ristad1993} raises: referential dependency in anaphora. Ristad argues that this is a problem we must solve to display competence of language, and yet it is rather difficult, justifying his broader conclusions about the nature of language.
\begin{quote}
    [E]very English speaker knows that \emph{Todd hurt him} cannot normally mean that `Todd hurt Todd'.
\end{quote}
The problem of working out which potential referents (e.g. Todd) must be excluded as candidates for a given referring expression (e.g. ‘him’) is, according to Ristad, very difficult—in terms of their number. But how often do we find, outside puzzles, that we have to simultaneously determine the referents of twenty or thirty pronouns? Perhaps not very often. If this applies to the other problems to which Ristad appeals, his broader thesis may be imperilled. In response, van Rooij and others have pointed out that many algorithms taking longer than polynomial time become intractable on anything but the smallest input. This argument, however, mostly involves the example of taking \(2^n\) time. With smaller exponential bases \parencite[see e.g.][]{hansen2019}, the range of feasible inputs might be large enough to include plausible bounds on non-trivial human cognitive tasks.